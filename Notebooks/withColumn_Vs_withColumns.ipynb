{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e1f1509-a9cd-43f5-aeb5-06401013de2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## withColumn Vs withColumns - Not much of performance difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7355f8d-4d00-4f71-81b0-ea0393410524",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Multiple withColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "521a9b09-2e05-4e2b-bc44-58d7560b8032",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df_1 = spark.sql(\"\"\"select * from samples.tpch.customer\"\"\")\n",
    "\n",
    "# Creating a list of list of columns that need to be instantiated as None\n",
    "dummy_col_list = ['foo1', 'foo2', 'foo3', 'foo4', 'foo5']\n",
    "\n",
    "# Using a for-loop to add these columns in dataframe\n",
    "for col_name in dummy_col_list:\n",
    "  df_1 = df_1.withColumn(col_name, lit(None).cast('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6464d09-c9e2-4f86-ac35-e735b901f374",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\nProject [c_custkey#101661L, c_name#101662, c_address#101663, c_nationkey#101664L, c_phone#101665, c_acctbal#101666, c_mktsegment#101667, c_comment#101668, foo1#101678, foo2#101688, foo3#101699, foo4#101711, cast(null as string) AS foo5#101724]\n+- Project [c_custkey#101661L, c_name#101662, c_address#101663, c_nationkey#101664L, c_phone#101665, c_acctbal#101666, c_mktsegment#101667, c_comment#101668, foo1#101678, foo2#101688, foo3#101699, cast(null as string) AS foo4#101711]\n   +- Project [c_custkey#101661L, c_name#101662, c_address#101663, c_nationkey#101664L, c_phone#101665, c_acctbal#101666, c_mktsegment#101667, c_comment#101668, foo1#101678, foo2#101688, cast(null as string) AS foo3#101699]\n      +- Project [c_custkey#101661L, c_name#101662, c_address#101663, c_nationkey#101664L, c_phone#101665, c_acctbal#101666, c_mktsegment#101667, c_comment#101668, foo1#101678, cast(null as string) AS foo2#101688]\n         +- Project [c_custkey#101661L, c_name#101662, c_address#101663, c_nationkey#101664L, c_phone#101665, c_acctbal#101666, c_mktsegment#101667, c_comment#101668, cast(null as string) AS foo1#101678]\n            +- Project [c_custkey#101661L, c_name#101662, c_address#101663, c_nationkey#101664L, c_phone#101665, c_acctbal#101666, c_mktsegment#101667, c_comment#101668]\n               +- SubqueryAlias samples.tpch.customer\n                  +- Relation samples.tpch.customer[c_custkey#101661L,c_name#101662,c_address#101663,c_nationkey#101664L,c_phone#101665,c_acctbal#101666,c_mktsegment#101667,c_comment#101668] parquet\n\n== Analyzed Logical Plan ==\nc_custkey: bigint, c_name: string, c_address: string, c_nationkey: bigint, c_phone: string, c_acctbal: decimal(18,2), c_mktsegment: string, c_comment: string, foo1: string, foo2: string, foo3: string, foo4: string, foo5: string\nProject [c_custkey#101661L, c_name#101662, c_address#101663, c_nationkey#101664L, c_phone#101665, c_acctbal#101666, c_mktsegment#101667, c_comment#101668, foo1#101678, foo2#101688, foo3#101699, foo4#101711, cast(null as string) AS foo5#101724]\n+- Project [c_custkey#101661L, c_name#101662, c_address#101663, c_nationkey#101664L, c_phone#101665, c_acctbal#101666, c_mktsegment#101667, c_comment#101668, foo1#101678, foo2#101688, foo3#101699, cast(null as string) AS foo4#101711]\n   +- Project [c_custkey#101661L, c_name#101662, c_address#101663, c_nationkey#101664L, c_phone#101665, c_acctbal#101666, c_mktsegment#101667, c_comment#101668, foo1#101678, foo2#101688, cast(null as string) AS foo3#101699]\n      +- Project [c_custkey#101661L, c_name#101662, c_address#101663, c_nationkey#101664L, c_phone#101665, c_acctbal#101666, c_mktsegment#101667, c_comment#101668, foo1#101678, cast(null as string) AS foo2#101688]\n         +- Project [c_custkey#101661L, c_name#101662, c_address#101663, c_nationkey#101664L, c_phone#101665, c_acctbal#101666, c_mktsegment#101667, c_comment#101668, cast(null as string) AS foo1#101678]\n            +- Project [c_custkey#101661L, c_name#101662, c_address#101663, c_nationkey#101664L, c_phone#101665, c_acctbal#101666, c_mktsegment#101667, c_comment#101668]\n               +- SubqueryAlias samples.tpch.customer\n                  +- Relation samples.tpch.customer[c_custkey#101661L,c_name#101662,c_address#101663,c_nationkey#101664L,c_phone#101665,c_acctbal#101666,c_mktsegment#101667,c_comment#101668] parquet\n\n== Optimized Logical Plan ==\nProject [c_custkey#101661L, c_name#101662, c_address#101663, c_nationkey#101664L, c_phone#101665, c_acctbal#101666, c_mktsegment#101667, c_comment#101668, null AS foo1#101678, null AS foo2#101688, null AS foo3#101699, null AS foo4#101711, null AS foo5#101724]\n+- Relation samples.tpch.customer[c_custkey#101661L,c_name#101662,c_address#101663,c_nationkey#101664L,c_phone#101665,c_acctbal#101666,c_mktsegment#101667,c_comment#101668] parquet\n\n== Physical Plan ==\n*(1) Project [c_custkey#101661L, c_name#101662, c_address#101663, c_nationkey#101664L, c_phone#101665, c_acctbal#101666, c_mktsegment#101667, c_comment#101668, null AS foo1#101678, null AS foo2#101688, null AS foo3#101699, null AS foo4#101711, null AS foo5#101724]\n+- *(1) ColumnarToRow\n   +- FileScan parquet samples.tpch.customer[c_custkey#101661L,c_name#101662,c_address#101663,c_nationkey#101664L,c_phone#101665,c_acctbal#101666,c_mktsegment#101667,c_comment#101668] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex(1 paths)[dbfs:/databricks-datasets/tpch/delta-001/customer], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<c_custkey:bigint,c_name:string,c_address:string,c_nationkey:bigint,c_phone:string,c_acctba...\n\n"
     ]
    }
   ],
   "source": [
    "df_1.explain(\"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89ac9eb9-06f7-4b22-a1e6-2d084e816808",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- c_custkey: long (nullable = true)\n |-- c_name: string (nullable = true)\n |-- c_address: string (nullable = true)\n |-- c_nationkey: long (nullable = true)\n |-- c_phone: string (nullable = true)\n |-- c_acctbal: decimal(18,2) (nullable = true)\n |-- c_mktsegment: string (nullable = true)\n |-- c_comment: string (nullable = true)\n |-- foo1: string (nullable = true)\n |-- foo2: string (nullable = true)\n |-- foo3: string (nullable = true)\n |-- foo4: string (nullable = true)\n |-- foo5: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89ff56df-4e6f-4db8-b2ab-95be913d5e30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df_2 = spark.sql(\"\"\"select * from samples.tpch.customer\"\"\")\n",
    "\n",
    "# Creating a list of list of columns that need to be instantiated as None\n",
    "dummy_col_list = ['foo1', 'foo2', 'foo3', 'foo4', 'foo5']\n",
    "\n",
    "# Using a for-loop to add these columns in dataframe\n",
    "for col_name in dummy_col_list:\n",
    "  df_3 = df_2.withColumn(col_name, lit(None).cast('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "721a7e70-312c-418f-88a9-85a8ab1b84e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\nProject [c_custkey#101747L, c_name#101748, c_address#101749, c_nationkey#101750L, c_phone#101751, c_acctbal#101752, c_mktsegment#101753, c_comment#101754, cast(null as string) AS foo5#101804]\n+- Project [c_custkey#101747L, c_name#101748, c_address#101749, c_nationkey#101750L, c_phone#101751, c_acctbal#101752, c_mktsegment#101753, c_comment#101754]\n   +- SubqueryAlias samples.tpch.customer\n      +- Relation samples.tpch.customer[c_custkey#101747L,c_name#101748,c_address#101749,c_nationkey#101750L,c_phone#101751,c_acctbal#101752,c_mktsegment#101753,c_comment#101754] parquet\n\n== Analyzed Logical Plan ==\nc_custkey: bigint, c_name: string, c_address: string, c_nationkey: bigint, c_phone: string, c_acctbal: decimal(18,2), c_mktsegment: string, c_comment: string, foo5: string\nProject [c_custkey#101747L, c_name#101748, c_address#101749, c_nationkey#101750L, c_phone#101751, c_acctbal#101752, c_mktsegment#101753, c_comment#101754, cast(null as string) AS foo5#101804]\n+- Project [c_custkey#101747L, c_name#101748, c_address#101749, c_nationkey#101750L, c_phone#101751, c_acctbal#101752, c_mktsegment#101753, c_comment#101754]\n   +- SubqueryAlias samples.tpch.customer\n      +- Relation samples.tpch.customer[c_custkey#101747L,c_name#101748,c_address#101749,c_nationkey#101750L,c_phone#101751,c_acctbal#101752,c_mktsegment#101753,c_comment#101754] parquet\n\n== Optimized Logical Plan ==\nProject [c_custkey#101747L, c_name#101748, c_address#101749, c_nationkey#101750L, c_phone#101751, c_acctbal#101752, c_mktsegment#101753, c_comment#101754, null AS foo5#101804]\n+- Relation samples.tpch.customer[c_custkey#101747L,c_name#101748,c_address#101749,c_nationkey#101750L,c_phone#101751,c_acctbal#101752,c_mktsegment#101753,c_comment#101754] parquet\n\n== Physical Plan ==\n*(1) Project [c_custkey#101747L, c_name#101748, c_address#101749, c_nationkey#101750L, c_phone#101751, c_acctbal#101752, c_mktsegment#101753, c_comment#101754, null AS foo5#101804]\n+- *(1) ColumnarToRow\n   +- FileScan parquet samples.tpch.customer[c_custkey#101747L,c_name#101748,c_address#101749,c_nationkey#101750L,c_phone#101751,c_acctbal#101752,c_mktsegment#101753,c_comment#101754] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex(1 paths)[dbfs:/databricks-datasets/tpch/delta-001/customer], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<c_custkey:bigint,c_name:string,c_address:string,c_nationkey:bigint,c_phone:string,c_acctba...\n\n"
     ]
    }
   ],
   "source": [
    "df_3.explain(\"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb9fd627-ce16-4cd2-881d-c3e77e9f2a84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\nProject [c_custkey#101995L, c_name#101996, c_address#101997, c_nationkey#101998L, c_phone#101999, c_acctbal#102000, c_mktsegment#102001, c_comment#102002, foo1#102012, foo2#102022, foo3#102033, foo4#102045, cast(null as string) AS foo5#102058]\n+- Project [c_custkey#101995L, c_name#101996, c_address#101997, c_nationkey#101998L, c_phone#101999, c_acctbal#102000, c_mktsegment#102001, c_comment#102002, foo1#102012, foo2#102022, foo3#102033, cast(null as string) AS foo4#102045]\n   +- Project [c_custkey#101995L, c_name#101996, c_address#101997, c_nationkey#101998L, c_phone#101999, c_acctbal#102000, c_mktsegment#102001, c_comment#102002, foo1#102012, foo2#102022, cast(null as string) AS foo3#102033]\n      +- Project [c_custkey#101995L, c_name#101996, c_address#101997, c_nationkey#101998L, c_phone#101999, c_acctbal#102000, c_mktsegment#102001, c_comment#102002, foo1#102012, cast(null as string) AS foo2#102022]\n         +- Project [c_custkey#101995L, c_name#101996, c_address#101997, c_nationkey#101998L, c_phone#101999, c_acctbal#102000, c_mktsegment#102001, c_comment#102002, cast(null as string) AS foo1#102012]\n            +- Project [c_custkey#101995L, c_name#101996, c_address#101997, c_nationkey#101998L, c_phone#101999, c_acctbal#102000, c_mktsegment#102001, c_comment#102002]\n               +- SubqueryAlias samples.tpch.customer\n                  +- Relation samples.tpch.customer[c_custkey#101995L,c_name#101996,c_address#101997,c_nationkey#101998L,c_phone#101999,c_acctbal#102000,c_mktsegment#102001,c_comment#102002] parquet\n\n== Analyzed Logical Plan ==\nc_custkey: bigint, c_name: string, c_address: string, c_nationkey: bigint, c_phone: string, c_acctbal: decimal(18,2), c_mktsegment: string, c_comment: string, foo1: string, foo2: string, foo3: string, foo4: string, foo5: string\nProject [c_custkey#101995L, c_name#101996, c_address#101997, c_nationkey#101998L, c_phone#101999, c_acctbal#102000, c_mktsegment#102001, c_comment#102002, foo1#102012, foo2#102022, foo3#102033, foo4#102045, cast(null as string) AS foo5#102058]\n+- Project [c_custkey#101995L, c_name#101996, c_address#101997, c_nationkey#101998L, c_phone#101999, c_acctbal#102000, c_mktsegment#102001, c_comment#102002, foo1#102012, foo2#102022, foo3#102033, cast(null as string) AS foo4#102045]\n   +- Project [c_custkey#101995L, c_name#101996, c_address#101997, c_nationkey#101998L, c_phone#101999, c_acctbal#102000, c_mktsegment#102001, c_comment#102002, foo1#102012, foo2#102022, cast(null as string) AS foo3#102033]\n      +- Project [c_custkey#101995L, c_name#101996, c_address#101997, c_nationkey#101998L, c_phone#101999, c_acctbal#102000, c_mktsegment#102001, c_comment#102002, foo1#102012, cast(null as string) AS foo2#102022]\n         +- Project [c_custkey#101995L, c_name#101996, c_address#101997, c_nationkey#101998L, c_phone#101999, c_acctbal#102000, c_mktsegment#102001, c_comment#102002, cast(null as string) AS foo1#102012]\n            +- Project [c_custkey#101995L, c_name#101996, c_address#101997, c_nationkey#101998L, c_phone#101999, c_acctbal#102000, c_mktsegment#102001, c_comment#102002]\n               +- SubqueryAlias samples.tpch.customer\n                  +- Relation samples.tpch.customer[c_custkey#101995L,c_name#101996,c_address#101997,c_nationkey#101998L,c_phone#101999,c_acctbal#102000,c_mktsegment#102001,c_comment#102002] parquet\n\n== Optimized Logical Plan ==\nProject [c_custkey#101995L, c_name#101996, c_address#101997, c_nationkey#101998L, c_phone#101999, c_acctbal#102000, c_mktsegment#102001, c_comment#102002, null AS foo1#102012, null AS foo2#102022, null AS foo3#102033, null AS foo4#102045, null AS foo5#102058]\n+- Relation samples.tpch.customer[c_custkey#101995L,c_name#101996,c_address#101997,c_nationkey#101998L,c_phone#101999,c_acctbal#102000,c_mktsegment#102001,c_comment#102002] parquet\n\n== Physical Plan ==\n*(1) Project [c_custkey#101995L, c_name#101996, c_address#101997, c_nationkey#101998L, c_phone#101999, c_acctbal#102000, c_mktsegment#102001, c_comment#102002, null AS foo1#102012, null AS foo2#102022, null AS foo3#102033, null AS foo4#102045, null AS foo5#102058]\n+- *(1) ColumnarToRow\n   +- FileScan parquet samples.tpch.customer[c_custkey#101995L,c_name#101996,c_address#101997,c_nationkey#101998L,c_phone#101999,c_acctbal#102000,c_mktsegment#102001,c_comment#102002] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex(1 paths)[dbfs:/databricks-datasets/tpch/delta-001/customer], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<c_custkey:bigint,c_name:string,c_address:string,c_nationkey:bigint,c_phone:string,c_acctba...\n\n"
     ]
    }
   ],
   "source": [
    "df_4 = spark.sql(\"\"\"select * from samples.tpch.customer\"\"\")\n",
    "\n",
    "df_4 = df_4.withColumn('foo1', lit(None).cast('string'))\\\n",
    "       .withColumn('foo2', lit(None).cast('string'))\\\n",
    "       .withColumn('foo3', lit(None).cast('string'))\\\n",
    "       .withColumn('foo4', lit(None).cast('string'))\\\n",
    "       .withColumn('foo5', lit(None).cast('string'))\n",
    "\n",
    "df_4.explain(\"extended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23b4600a-06e5-4db5-8c62-a750b53359d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We can see multiple projects for every column added in analyzed logical plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ab2a416-eb13-42af-9394-bbc898346f7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Using withColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7ddedf0-00e0-4727-889c-62da214d28ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\nProject [c_custkey#102169L, c_name#102170, c_address#102171, c_nationkey#102172L, c_phone#102173, c_acctbal#102174, c_mktsegment#102175, c_comment#102176, cast(null as string) AS foo1#102186, cast(null as string) AS foo2#102187, cast(null as string) AS foo3#102188, cast(null as string) AS foo4#102189, cast(null as string) AS foo5#102190]\n+- Project [c_custkey#102169L, c_name#102170, c_address#102171, c_nationkey#102172L, c_phone#102173, c_acctbal#102174, c_mktsegment#102175, c_comment#102176]\n   +- SubqueryAlias samples.tpch.customer\n      +- Relation samples.tpch.customer[c_custkey#102169L,c_name#102170,c_address#102171,c_nationkey#102172L,c_phone#102173,c_acctbal#102174,c_mktsegment#102175,c_comment#102176] parquet\n\n== Analyzed Logical Plan ==\nc_custkey: bigint, c_name: string, c_address: string, c_nationkey: bigint, c_phone: string, c_acctbal: decimal(18,2), c_mktsegment: string, c_comment: string, foo1: string, foo2: string, foo3: string, foo4: string, foo5: string\nProject [c_custkey#102169L, c_name#102170, c_address#102171, c_nationkey#102172L, c_phone#102173, c_acctbal#102174, c_mktsegment#102175, c_comment#102176, cast(null as string) AS foo1#102186, cast(null as string) AS foo2#102187, cast(null as string) AS foo3#102188, cast(null as string) AS foo4#102189, cast(null as string) AS foo5#102190]\n+- Project [c_custkey#102169L, c_name#102170, c_address#102171, c_nationkey#102172L, c_phone#102173, c_acctbal#102174, c_mktsegment#102175, c_comment#102176]\n   +- SubqueryAlias samples.tpch.customer\n      +- Relation samples.tpch.customer[c_custkey#102169L,c_name#102170,c_address#102171,c_nationkey#102172L,c_phone#102173,c_acctbal#102174,c_mktsegment#102175,c_comment#102176] parquet\n\n== Optimized Logical Plan ==\nProject [c_custkey#102169L, c_name#102170, c_address#102171, c_nationkey#102172L, c_phone#102173, c_acctbal#102174, c_mktsegment#102175, c_comment#102176, null AS foo1#102186, null AS foo2#102187, null AS foo3#102188, null AS foo4#102189, null AS foo5#102190]\n+- Relation samples.tpch.customer[c_custkey#102169L,c_name#102170,c_address#102171,c_nationkey#102172L,c_phone#102173,c_acctbal#102174,c_mktsegment#102175,c_comment#102176] parquet\n\n== Physical Plan ==\n*(1) Project [c_custkey#102169L, c_name#102170, c_address#102171, c_nationkey#102172L, c_phone#102173, c_acctbal#102174, c_mktsegment#102175, c_comment#102176, null AS foo1#102186, null AS foo2#102187, null AS foo3#102188, null AS foo4#102189, null AS foo5#102190]\n+- *(1) ColumnarToRow\n   +- FileScan parquet samples.tpch.customer[c_custkey#102169L,c_name#102170,c_address#102171,c_nationkey#102172L,c_phone#102173,c_acctbal#102174,c_mktsegment#102175,c_comment#102176] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex(1 paths)[dbfs:/databricks-datasets/tpch/delta-001/customer], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<c_custkey:bigint,c_name:string,c_address:string,c_nationkey:bigint,c_phone:string,c_acctba...\n\n"
     ]
    }
   ],
   "source": [
    "df_5 = spark.sql(\"\"\"select * from samples.tpch.customer\"\"\")\n",
    "\n",
    "# Creating a dictionary for the static columns\n",
    "dummy_col_val_map = {\n",
    "  'foo1': lit(None).cast('string'), \n",
    "  'foo2': lit(None).cast('string'), \n",
    "  'foo3': lit(None).cast('string'), \n",
    "  'foo4': lit(None).cast('string'), \n",
    "  'foo5': lit(None).cast('string')\n",
    "}\n",
    "\n",
    "# Adding columns using withColumns\n",
    "df_5 = df_5.withColumns(dummy_col_val_map)\n",
    "\n",
    "df_5.explain(\"extended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d5f8deb-7507-4e50-b2f0-2d8ed71b5f57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Single project node in analyzed logical plan when withColumns is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14b10ec0-232e-47cd-9b67-db663ef2e28d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Using .select() with an alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68cb2fee-2d8a-472c-a0ed-f8bd6a3106c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n'Project [*, cast(null as string) AS foo1#1207, cast(null as string) AS foo2#1208, cast(null as string) AS foo3#1209, cast(null as string) AS foo4#1210, cast(null as string) AS foo5#1211]\n+- Project [c_custkey#1190L, c_name#1191, c_address#1192, c_nationkey#1193L, c_phone#1194, c_acctbal#1195, c_mktsegment#1196, c_comment#1197]\n   +- SubqueryAlias samples.tpch.customer\n      +- Relation samples.tpch.customer[c_custkey#1190L,c_name#1191,c_address#1192,c_nationkey#1193L,c_phone#1194,c_acctbal#1195,c_mktsegment#1196,c_comment#1197] parquet\n\n== Analyzed Logical Plan ==\nc_custkey: bigint, c_name: string, c_address: string, c_nationkey: bigint, c_phone: string, c_acctbal: decimal(18,2), c_mktsegment: string, c_comment: string, foo1: string, foo2: string, foo3: string, foo4: string, foo5: string\nProject [c_custkey#1190L, c_name#1191, c_address#1192, c_nationkey#1193L, c_phone#1194, c_acctbal#1195, c_mktsegment#1196, c_comment#1197, cast(null as string) AS foo1#1207, cast(null as string) AS foo2#1208, cast(null as string) AS foo3#1209, cast(null as string) AS foo4#1210, cast(null as string) AS foo5#1211]\n+- Project [c_custkey#1190L, c_name#1191, c_address#1192, c_nationkey#1193L, c_phone#1194, c_acctbal#1195, c_mktsegment#1196, c_comment#1197]\n   +- SubqueryAlias samples.tpch.customer\n      +- Relation samples.tpch.customer[c_custkey#1190L,c_name#1191,c_address#1192,c_nationkey#1193L,c_phone#1194,c_acctbal#1195,c_mktsegment#1196,c_comment#1197] parquet\n\n== Optimized Logical Plan ==\nProject [c_custkey#1190L, c_name#1191, c_address#1192, c_nationkey#1193L, c_phone#1194, c_acctbal#1195, c_mktsegment#1196, c_comment#1197, null AS foo1#1207, null AS foo2#1208, null AS foo3#1209, null AS foo4#1210, null AS foo5#1211]\n+- Relation samples.tpch.customer[c_custkey#1190L,c_name#1191,c_address#1192,c_nationkey#1193L,c_phone#1194,c_acctbal#1195,c_mktsegment#1196,c_comment#1197] parquet\n\n== Physical Plan ==\n*(1) Project [c_custkey#1190L, c_name#1191, c_address#1192, c_nationkey#1193L, c_phone#1194, c_acctbal#1195, c_mktsegment#1196, c_comment#1197, null AS foo1#1207, null AS foo2#1208, null AS foo3#1209, null AS foo4#1210, null AS foo5#1211]\n+- *(1) ColumnarToRow\n   +- FileScan parquet samples.tpch.customer[c_custkey#1190L,c_name#1191,c_address#1192,c_nationkey#1193L,c_phone#1194,c_acctbal#1195,c_mktsegment#1196,c_comment#1197] Batched: true, DataFilters: [], Format: Parquet, Location: PreparedDeltaFileIndex(1 paths)[dbfs:/databricks-datasets/tpch/delta-001/customer], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<c_custkey:bigint,c_name:string,c_address:string,c_nationkey:bigint,c_phone:string,c_acctba...\n\n"
     ]
    }
   ],
   "source": [
    "df_1 = spark.sql(\"\"\"select * from samples.tpch.customer\"\"\")\n",
    "\n",
    "# Using .select with alias\n",
    "df_1 = df_1.select(\"*\", *[cvalue.alias(cname) for cname, cvalue in dummy_col_val_map.items()])\n",
    "\n",
    "df_1.explain(\"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd2eacf1-8a32-4f35-b327-a834fe7d7881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.adaptive.enabled\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84fe019f-25f6-49ef-b93b-f860171eacf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== Metrics of Analyzer/Optimizer Rules ===\nTotal number of runs: 366688\nTotal time: 146.009936957 seconds\n\nRule                                                                                               Effective Time / Total Time                     Effective Runs / Total Runs                    \n\norg.apache.spark.sql.catalyst.analysis.Analyzer$AddMetadataColumns                                 0 / 63458891256                                 0 / 4025                                       \norg.apache.spark.sql.catalyst.plans.logical.ConvertSecureViewUnaryNodeToLeafNode                   0 / 33635693047                                 0 / 2014                                       \norg.apache.spark.sql.catalyst.analysis.DeduplicateRelations                                        0 / 30267194693                                 0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations                                   10551620626 / 10705144159                       4 / 4025                                       \ncom.databricks.sql.analyzer.ResolveRowColumnAccessControls                                         0 / 1773479706                                  0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences                                  58047882 / 863185583                            8 / 4025                                       \ncom.databricks.sql.transaction.tahoe.DeltaAnalysis                                                 455574622 / 533873211                           4 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.TypeCoercionBase$CombinedTypeCoercionRule                   0 / 492605163                                   0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.UpdateAttributeNullability                                  0 / 489462141                                   0 / 2016                                       \norg.apache.spark.sql.catalyst.analysis.ResolveTimeZone                                             280113479 / 340350152                           2003 / 4025                                    \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRandomSeed                                  0 / 265284671                                   0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.TypeCoercionBase$WidenSetOperationTypes                     0 / 214843830                                   0 / 4025                                       \norg.apache.spark.sql.execution.analysis.DetectAmbiguousSelfJoin                                    0 / 202478740                                   0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.ResolveSessionCatalog                                       0 / 164938198                                   0 / 4025                                       \norg.apache.spark.sql.execution.aggregate.ResolveEncodersInScalaAgg                                 0 / 118455731                                   0 / 4025                                       \ncom.databricks.sql.transaction.tahoe.DeltaAnalysisEdge                                             0 / 116691782                                   0 / 2013                                       \norg.apache.spark.sql.catalyst.optimizer.OptimizeUpdateFields                                       0 / 72319688                                    0 / 2016                                       \norg.apache.spark.sql.catalyst.analysis.CleanupAliases                                              0 / 65065112                                    0 / 2013                                       \norg.apache.spark.sql.execution.datasources.FindDataSourceTable                                     0 / 50894053                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAliases                                     42812041 / 48715145                             1 / 4025                                       \norg.apache.spark.sql.catalyst.optimizer.Optimizer$FinishAnalysis                                   0 / 48559187                                    0 / 1                                          \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveBinaryArithmetic                            0 / 47103325                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.ResolveCatalogs                                             0 / 43004553                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveDeserializer                                33435020 / 42268400                             1 / 4025                                       \ncom.databricks.sql.dlt.EventLogAnalysis                                                            0 / 40517668                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.ResolveDefaultColumns                                       0 / 37476861                                    0 / 4025                                       \ncom.databricks.sql.managedcatalog.ResolveWithCredential                                            0 / 33241032                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.optimizer.OptimizeOneRowRelationSubquery                             0 / 32749620                                    0 / 1                                          \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveTimeTravel                                  0 / 31522657                                    0 / 4025                                       \norg.apache.spark.sql.execution.datasources.DataSourceAnalysis                                      0 / 28259337                                    0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.RewriteDeleteFromTable                                      0 / 27688037                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveFieldNameAndPosition                        0 / 27581172                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.optimizer.ColumnPruning                                              26381258 / 27419552                             1 / 6                                          \norg.apache.spark.sql.hive.RelationConversions                                                      0 / 26807999                                    0 / 2013                                       \norg.apache.spark.sql.catalyst.optimizer.ConvertToLocalRelation                                     21791314 / 26681456                             1 / 3                                          \ncom.databricks.sql.acl.InlineUserInfoExpressions                                                   0 / 24998037                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveFunctions                                   0 / 23351715                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.optimizer.BooleanSimplification                                      0 / 22867558                                    0 / 5                                          \norg.apache.spark.sql.catalyst.optimizer.PushDownPredicates                                         21362119 / 21581414                             1 / 8                                          \ncom.databricks.sql.cloudfiles.CloudFilesAnalysis                                                   0 / 21390090                                    0 / 4025                                       \ncom.databricks.sql.optimizer.FilterReduction                                                       0 / 21296256                                    0 / 3                                          \norg.apache.spark.sql.catalyst.analysis.Analyzer$SparkServiceStatementSubstitution                  0 / 21247279                                    0 / 2013                                       \norg.apache.spark.sql.execution.datasources.ApplyCharTypePadding                                    0 / 20826788                                    0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveUpCast                                      11258335 / 20661495                             1 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.ResolveLambdaVariables                                      0 / 20606289                                    0 / 4025                                       \ncom.databricks.sql.optimizer.RangeJoinRewrite                                                      0 / 20233964                                    0 / 1                                          \norg.apache.spark.sql.catalyst.analysis.ResolveExpressionsWithNamePlaceholders                      0 / 20070025                                    0 / 4025                                       \ncom.databricks.sql.transaction.tahoe.stats.PrepareDeltaScan                                        0 / 16781581                                    0 / 1                                          \norg.apache.spark.sql.execution.streaming.ResolveWriteToStream                                      0 / 16540402                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.EliminateEventTimeWatermark                                 0 / 16192565                                    0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.ResolveLateralColumnAliasReference                          0 / 16170793                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveUnpivot                                     0 / 16009683                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.optimizer.MergeScalarSubqueries                                      0 / 15772720                                    0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.PruneFilters                                               0 / 15726946                                    0 / 4                                          \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveInsertInto                                  0 / 15632724                                    0 / 4025                                       \norg.apache.spark.sql.execution.datasources.ResolveSQLOnFile                                        0 / 15514639                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.optimizer.NullPropagation                                            0 / 15386980                                    0 / 4                                          \norg.apache.spark.sql.execution.datasources.PreprocessTableInsertion                                0 / 15243652                                    0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$GlobalAggregates                                   0 / 14842555                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot                                       0 / 14800692                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveSQLFunctions                                0 / 14653262                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.TimeWindowing                                               0 / 14391189                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.optimizer.InferFiltersFromConstraints                                0 / 14180690                                    0 / 2                                          \norg.apache.spark.sql.catalyst.analysis.UpdateOuterReferences                                       0 / 14102009                                    0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.ResolveInlineTables                                         0 / 13941157                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.EvalSubqueriesForTimeTravel                                 0 / 13592221                                    0 / 4025                                       \ncom.databricks.sql.optimizer.SpecializeScalaUDF                                                    0 / 13552775                                    0 / 1                                          \norg.apache.spark.sql.catalyst.analysis.EliminateUnions                                             0 / 13420567                                    0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveUserSpecifiedColumns                        0 / 13344415                                    0 / 4025                                       \norg.apache.spark.sql.hive.ResolveHiveSerdeTable                                                    0 / 12889668                                    0 / 4025                                       \norg.apache.spark.sql.execution.datasources.PreprocessTableCreation                                 0 / 12673443                                    0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.ResolveUnion                                                0 / 12658203                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions                           0 / 12370950                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.SubstituteUnresolvedOrdinals                                0 / 12225009                                    0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveSubquery                                    0 / 12016122                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.RemoveTempResolvedColumn                                    0 / 12003967                                    0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.BindParameters                                              0 / 11968134                                    0 / 2013                                       \ncom.databricks.sql.analyzer.ResolveRangeJoinHints                                                  0 / 11822720                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggregateFunctions                          0 / 11781686                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ExtractGenerator                                   0 / 11724469                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$WindowsSubstitution                                0 / 11523807                                    0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions                                    0 / 11510648                                    0 / 2013                                       \ncom.databricks.sql.transaction.tahoe.PreprocessTableUpdateEdge                                     0 / 11480001                                    0 / 2013                                       \norg.apache.spark.sql.execution.datasources.v2.V2ScanRelationPushDown                               0 / 11421660                                    0 / 1                                          \ncom.databricks.sql.expressions.ExtractSemiStructuredFields                                         0 / 11400115                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveNewInstance                                 0 / 11113748                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveQualify                                     0 / 11111095                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGenerate                                    0 / 10998031                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.TypeCoercionBase$UnpivotCoercion                            0 / 10982768                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveWindowFrame                                 0 / 10874964                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.KeepLegacyOutputs                                           0 / 10655786                                    0 / 2013                                       \norg.apache.spark.sql.execution.datasources.SchemaPruning                                           0 / 10533042                                    0 / 1                                          \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveSQLTableFunctions                           0 / 10467977                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.ResolvePartitionSpec                                        0 / 10340043                                    0 / 4025                                       \ncom.databricks.sql.acl.ResolvePermissionManagement                                                 0 / 10202522                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.SessionWindowing                                            0 / 10199583                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveSubqueryColumnAliases                       0 / 10165021                                    0 / 4025                                       \norg.apache.spark.sql.execution.datasources.FallBackFileSourceV2                                    0 / 10145880                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.ResolveHints$ResolveDynamicPartitionPruningHints            0 / 10132812                                    0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveOrdinalInOrderByAndGroupBy                  0 / 10112757                                    0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.ResolveWithCTE                                              0 / 10029784                                    0 / 4025                                       \norg.apache.spark.sql.hive.DetermineTableStats                                                      0 / 9828046                                     0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveWindowOrder                                 0 / 9769537                                     0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.PullOutNondeterministic                                     0 / 9674263                                     0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$HandleNullInputsForUDF                             0 / 9575367                                     0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.ResolveHints$RemoveAllHints                                 0 / 9423026                                     0 / 2013                                       \ncom.databricks.service.ClientPlaceholderAnalysis                                                   0 / 9237286                                     0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.ResolveWindowTime                                           0 / 8906337                                     0 / 4025                                       \ncom.databricks.sql.analyzer.CheckNestedRowColumnAccess                                             0 / 8880479                                     0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveNaturalAndUsingJoin                         0 / 8725730                                     0 / 4025                                       \norg.apache.spark.sql.catalyst.optimizer.SimplifyExtractValueOps                                    0 / 8700220                                     0 / 3                                          \ncom.databricks.sql.transaction.tahoe.PreprocessTableMergeEdge                                      0 / 8671434                                     0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.ResolveHints$ResolveJoinStrategyHints                       0 / 8653684                                     0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.ResolveCommandsWithIfExists                                 0 / 8645465                                     0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$HandleSpecialCommand                               0 / 8369226                                     0 / 2013                                       \ncom.databricks.sql.transaction.tahoe.PreprocessTableDeleteEdge                                     0 / 8354794                                     0 / 2013                                       \norg.apache.spark.sql.catalyst.analysis.ResolveHints$DisableHints                                   0 / 8277717                                     0 / 2013                                       \norg.apache.spark.sql.execution.datasources.v2.V2Writes                                             0 / 8225169                                     0 / 1                                          \ncom.databricks.sql.expressions.OptimizeMultiSemiStructuredExtract                                  0 / 8140386                                     0 / 1                                          \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveOutputRelation                              0 / 8089597                                     0 / 4025                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics                           0 / 7913457                                     0 / 4025                                       \norg.apache.spark.sql.catalyst.optimizer.RewriteLateralSubquery                                     0 / 7912265                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.OptimizeCsvJsonExprs                                       0 / 7816543                                     0 / 3                                          \norg.apache.spark.sql.catalyst.analysis.ResolveHints$ResolveCoalesceHints                           0 / 7765554                                     0 / 2013                                       \norg.apache.spark.sql.hive.HiveAnalysis                                                             0 / 7653922                                     0 / 2013                                       \norg.apache.spark.sql.catalyst.optimizer.RewriteCorrelatedScalarSubquery                            0 / 7577818                                     0 / 3                                          \norg.apache.spark.sql.execution.datasources.PruneFileSourcePartitions                               0 / 7500260               \n\n*** WARNING: max output size exceeded, skipping output. ***\n\n                                 \norg.apache.spark.sql.execution.datasources.v2.V2ScanPartitioningAndOrdering                        0 / 3753452                                     0 / 1                                          \norg.apache.spark.sql.catalyst.expressions.codegen.package$ExpressionCanonicalizer$CleanExpressions 0 / 3741837                                     0 / 3                                          \ncom.databricks.sql.optimizer.SimplifyStringFunctions                                               0 / 3732446                                     0 / 3                                          \ncom.databricks.sql.optimizer.CombineApproximatePercentileAggregates                                0 / 3722593                                     0 / 3                                          \ncom.databricks.sql.analyzer.CheckRowColumnAccessFunctionsInReferencedTables                        0 / 3704250                                     0 / 4025                                       \ncom.databricks.sql.optimizer.FilterPredicateSimplification                                         0 / 3700073                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.RemoveNoopOperators                                        0 / 3599791                                     0 / 7                                          \ncom.databricks.sql.optimizer.OptimizeArrayNullCheck                                                0 / 3599508                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.RewriteExceptAll                                           0 / 3595965                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.PushFoldableIntoBranches                                   0 / 3587839                                     0 / 3                                          \ncom.databricks.sql.optimizer.SkewJoinRewrite                                                       0 / 3562893                                     0 / 1                                          \ncom.databricks.sql.optimizer.EliminateRedundantAggregatePart                                       0 / 3542678                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.InjectRuntimeFilter                                        0 / 3529889                                     0 / 2                                          \norg.apache.spark.sql.catalyst.optimizer.CombineConcats                                             0 / 3508284                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.EliminateOuterJoin                                         0 / 3406899                                     0 / 3                                          \ncom.databricks.sql.optimizer.SimplifyRLike                                                         0 / 3392660                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.SimplifyCaseConversionExpressions                          0 / 3380324                                     0 / 3                                          \ncom.databricks.sql.optimizer.PushDownExtractValueExpressions                                       0 / 3375805                                     0 / 3                                          \ncom.databricks.sql.optimizer.PushExtractValueIntoArrayTransform                                    0 / 3370362                                     0 / 3                                          \norg.apache.spark.sql.execution.dynamicpruning.PartitionPruning                                     0 / 3365095                                     0 / 1                                          \ncom.databricks.sql.optimizer.EliminateNullCheckForExtractValue                                     0 / 3340182                                     0 / 3                                          \norg.apache.spark.sql.execution.datasources.v2.GroupBasedRowLevelOperationScanPlanning              0 / 3326189                                     0 / 1                                          \norg.apache.spark.sql.execution.dynamicpruning.CleanupDynamicPruningFilters                         0 / 3325030                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.RemoveDispensableExpressions                               0 / 3284453                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.LimitPushDownThroughWindow                                 0 / 3201376                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.PushLeftSemiLeftAntiThroughJoin                            0 / 3128912                                     0 / 3                                          \ncom.databricks.sql.optimizer.PushLimitIntoAggregate                                                0 / 3101399                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.RemoveRedundantAggregates                                  0 / 3090946                                     0 / 4                                          \norg.apache.spark.sql.catalyst.optimizer.SimplifyConditionals                                       0 / 3039644                                     0 / 3                                          \ncom.databricks.sql.optimizer.ComplexTypeMinMax                                                     0 / 2969085                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.SimplifyBinaryComparison                                   0 / 2966387                                     0 / 3                                          \ncom.databricks.sql.optimizer.PropagateEmptyRelationThroughAggregate                                0 / 2958843                                     0 / 2                                          \norg.apache.spark.sql.hive.execution.PruneHiveTablePartitions                                       0 / 2955526                                     0 / 1                                          \ncom.databricks.sql.optimizer.DynamicFilterPropagation                                              0 / 2944549                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.EliminateLimits                                            0 / 2875162                                     0 / 3                                          \ncom.databricks.sql.optimizer.JoinORExpansion                                                       0 / 2839744                                     0 / 1                                          \ncom.databricks.sql.optimizer.EliminateSecureViewNode                                               0 / 2823451                                     0 / 3                                          \ncom.databricks.sql.optimizer.OptimizeArrayContains                                                 0 / 2794119                                     0 / 3                                          \norg.apache.spark.sql.catalyst.plans.logical.ConvertSecureViewLeafNodeToUnaryNode                   0 / 2773168                                     0 / 2                                          \norg.apache.spark.sql.catalyst.optimizer.OptimizeRand                                               0 / 2753819                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.CombineUnions                                              0 / 2744965                                     0 / 4                                          \norg.apache.spark.sql.catalyst.optimizer.GenerateOptimization                                       0 / 2711125                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.ObjectSerializerPruning                                    0 / 2697964                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.PushProjectionThroughLimit                                 0 / 2696874                                     0 / 5                                          \ncom.databricks.sql.optimizer.FilePruning                                                           0 / 2669704                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.CollapseRepartition                                        0 / 2668030                                     0 / 3                                          \ncom.databricks.sql.optimizer.ConvertCollectSetToCollectListDistinct                                0 / 2639728                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.RemoveLiteralFromGroupExpressions                          0 / 2636623                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.ReplaceUpdateFieldsExpression                              0 / 2636000                                     0 / 1                                          \ncom.databricks.sql.optimizer.SimplifyRegExpReplace                                                 0 / 2625001                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.NormalizeFloatingNumbers                                   0 / 2602461                                     0 / 1                                          \norg.apache.spark.sql.execution.python.ExtractPythonUDFFromAggregate                                0 / 2600681                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.Optimizer$OptimizeSubqueries                               0 / 2549987                                     0 / 1                                          \ncom.databricks.sql.optimizer.CollapseMultipleWindowSpec                                            0 / 2521917                                     0 / 1                                          \ncom.databricks.sql.optimizer.OptimizeCase                                                          0 / 2491480                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.LikeSimplification                                         0 / 2459341                                     0 / 3                                          \ncom.databricks.sql.optimizer.EdgeNormalizeExpressions                                              0 / 2448292                                     0 / 3                                          \ncom.databricks.sql.optimizer.EliminateRedundantDistinctInAggregateFunction                         0 / 2447383                                     0 / 3                                          \ncom.databricks.sql.optimizer.NormalizeAggregateFilter                                              0 / 2427637                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.DecimalAggregates                                          0 / 2389282                                     0 / 1                                          \ncom.databricks.sql.optimizer.ReplaceEqualToWithNullEqInJoin                                        0 / 2386875                                     0 / 3                                          \ncom.databricks.sql.optimizer.OptimizeArraySize                                                     0 / 2366092                                     0 / 1                                          \ncom.databricks.sql.optimizer.PushDownGetArrayItemToStringSplit                                     0 / 2345971                                     0 / 3                                          \ncom.databricks.sql.optimizer.OptimizeSample                                                        0 / 2336698                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.ReplaceIntersectWithSemiJoin                               0 / 2278254                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.FoldablePropagation                                        0 / 2264107                                     0 / 4                                          \norg.apache.spark.sql.catalyst.optimizer.ReorderAssociativeOperator                                 0 / 2214737                                     0 / 3                                          \ncom.databricks.sql.optimizer.FoldEmptyAggregate                                                    0 / 2156487                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.OptimizeOneRowPlan                                         0 / 2148547                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.ReplaceExceptWithAntiJoin                                  0 / 2142838                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.EliminateOffsets                                           0 / 2073146                                     0 / 3                                          \ncom.databricks.sql.optimizer.SimplifyUnderscoreLike                                                0 / 2049423                                     0 / 3                                          \ncom.databricks.sql.optimizer.ReduceSubstringMaterialization                                        0 / 2045749                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.CleanUpTempCTEInfo                                         0 / 2040528                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.RemoveRepetitionFromGroupExpressions                       0 / 1981581                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.RewriteDistinctAggregates                                  0 / 1964544                                     0 / 2                                          \norg.apache.spark.sql.catalyst.optimizer.CombineTypedFilters                                        0 / 1893186                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.ReplaceDistinctWithAggregate                               0 / 1869747                                     0 / 1                                          \ncom.databricks.sql.transaction.tahoe.perf.DescribeHistoryLimitPushdown                             0 / 1833879                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.OptimizeIn                                                 0 / 1828756                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.OptimizeRepartition                                        0 / 1824699                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.PushProjectionThroughUnion                                 0 / 1781694                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.EliminateMapObjects                                        0 / 1759942                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.ReplaceExceptWithFilter                                    0 / 1738433                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.ReplaceDeduplicateWithAggregate                            0 / 1692969                                     0 / 1                                          \norg.apache.spark.sql.execution.datasources.V1Writes                                                0 / 1672403                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.ReassignLambdaVariableID                                   0 / 1545192                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.RemoveNoopUnion                                            0 / 1517202                                     0 / 1                                          \ncom.databricks.sql.optimizer.ExtractPythonUDFFromWindow                                            0 / 1487939                                     0 / 1                                          \norg.apache.spark.sql.execution.python.ExtractGroupingPythonUDFFromAggregate                        0 / 1261261                                     0 / 1                                          \norg.apache.spark.sql.execution.python.ExtractPythonUDFs                                            0 / 942502                                      0 / 1                                          \ncom.databricks.sql.optimizer.ConvertInnerToSemiJoins                                               0 / 931272                                      0 / 1                                          \norg.apache.spark.sql.execution.dynamicpruning.RowLevelOperationRuntimeGroupFiltering               0 / 856937                                      0 / 1                                          \ncom.databricks.sql.streaming.perf.MoveOptimizedForEachBatchFastpathToRoot                          0 / 632550                                      0 / 1                                          \ncom.databricks.sql.optimizer.RangePartitionIdRewrite                                               0 / 610204                                      0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.RemoveRedundantAliases                                     0 / 548123                                      0 / 5                                          \norg.apache.spark.sql.catalyst.optimizer.CombineFilters                                             0 / 526285                                      0 / 4                                          \ncom.databricks.sql.optimizer.OptimizeLimit                                                         0 / 483830                                      0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.EliminateSorts                                             0 / 345378                                      0 / 1                                          \ncom.databricks.sql.optimizer.CombineCountSumAverage                                                0 / 202404                                      0 / 3                                          \ncom.databricks.sql.optimizer.OptimizeGroupByChain                                                  0 / 152692                                      0 / 4                                          \ncom.databricks.sql.optimizer.ShuffleAndReduceDivisions                                             0 / 94554                                       0 / 3                                          \ncom.databricks.sql.execution.safespark.IsolatePysparkUDFs                                          0 / 88492                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.DisableExpressionCodegenOverLocalRelations                 0 / 70498                                       0 / 1                                          \ncom.databricks.sql.optimizer.PredicateReorder                                                      0 / 66480                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.CheckCartesianProducts                                     0 / 65306                                       0 / 2                                          \ncom.databricks.sql.optimizer.CollectDynamicPruningBroadcastKeys                                    0 / 64801                                       0 / 1                                          \ncom.databricks.service.CheckProtoSerializable                                                      0 / 62556                                       0 / 1                                          \ncom.databricks.sql.optimizer.AggregatePushdown                                                     0 / 57064                                       0 / 1                                          \ncom.databricks.aether.experimental.InsertMetadataSubplans                                          0 / 56963                                       0 / 1                                          \ncom.databricks.sql.optimizer.TransformShrinkingToGrowing                                           0 / 52806                                       0 / 1                                          \ncom.databricks.sql.optimizer.RewriteCastAsTryCast                                                  0 / 52473                                       0 / 3                                          \ncom.databricks.sql.io.parquet.ParquetSchemaPruning                                                 0 / 46487                                       0 / 1                                          \ncom.databricks.service.ConvertRemoteExec                                                           0 / 33661                                       0 / 1                                          \ncom.databricks.sql.execution.safespark.ExtractExternalUDFs                                         0 / 31227                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.SimplifyCasts                                              0 / 31170                                       0 / 3                                          \ncom.databricks.sql.streaming.perf.InjectOptimizedForEachBatchFastpathNodeToInnerQuery              0 / 30485                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.ReplaceCTERefWithRepartition                               0 / 24208                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin                                   0 / 21748                                       0 / 1                                          \norg.apache.spark.sql.execution.OptimizeMetadataOnlyQuery                                           0 / 21007                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.PushPredicateThroughNonJoin                                0 / 17897                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.PullOutGroupingExpressions                                 0 / 17232                                       0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.PushdownPredicatesAndPruneColumnsForCTEDef                 0 / 16579                                       0 / 3                                          \ncom.databricks.sql.optimizer.CaseWhenToMapLookUp                                                   0 / 14851                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.Optimizer$UpdateCTERelationStats                           0 / 13320                                       0 / 1                                          \ncom.databricks.sql.streaming.perf.CollapseOptimizedForEachBatchFastpath                            0 / 11463                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.InlineCTE                                                  0 / 6430                                        0 / 1                                          \ncom.databricks.service.NoOpRule                                                                    0 / 6040                                        0 / 4                                          \n     \n"
     ]
    }
   ],
   "source": [
    "# Checking time taken by rule executor for withColumn\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "df_1 = spark.sql(\"\"\"select * from samples.tpch.customer\"\"\")\n",
    "\n",
    "# lets create 300 dummy column list\n",
    "dummy_col_list = [f\"foo{i}\" for i in range(1,1001)]\n",
    "\n",
    "# Get JVM reference\n",
    "jvm = spark.sparkContext._jvm\n",
    "\n",
    "# Access Scala package/class\n",
    "catalyst_rule_executor = jvm.org.apache.spark.sql.catalyst.rules.RuleExecutor\n",
    "\n",
    "# Adding 300 columns\n",
    "for col_name in dummy_col_list:\n",
    "  df_2 = df_1.withColumn(col_name, lit(None).cast('string'))\n",
    "\n",
    "print(catalyst_rule_executor.dumpTimeSpent())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35157ee8-ee9b-4722-9f6b-844f3276a4a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== Metrics of Analyzer/Optimizer Rules ===\nTotal number of runs: 184506\nTotal time: 145.094955828 seconds\n\nRule                                                                                               Effective Time / Total Time                     Effective Runs / Total Runs                    \n\norg.apache.spark.sql.catalyst.analysis.Analyzer$AddMetadataColumns                                 0 / 63381162118                                 0 / 2023                                       \norg.apache.spark.sql.catalyst.plans.logical.ConvertSecureViewUnaryNodeToLeafNode                   0 / 33623253777                                 0 / 1013                                       \norg.apache.spark.sql.catalyst.analysis.DeduplicateRelations                                        0 / 30235319019                                 0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations                                   10349759220 / 10459211567                       3 / 2023                                       \ncom.databricks.sql.analyzer.ResolveRowColumnAccessControls                                         0 / 1748285431                                  0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences                                  57957411 / 819587995                            7 / 2023                                       \ncom.databricks.sql.transaction.tahoe.DeltaAnalysis                                                 450457006 / 520944181                           3 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.UpdateAttributeNullability                                  0 / 461720786                                   0 / 1015                                       \norg.apache.spark.sql.catalyst.analysis.TypeCoercionBase$CombinedTypeCoercionRule                   0 / 454317192                                   0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.ResolveTimeZone                                             229849725 / 284778248                           1003 / 2023                                    \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRandomSeed                                  0 / 241233055                                   0 / 2023                                       \norg.apache.spark.sql.execution.analysis.DetectAmbiguousSelfJoin                                    0 / 195978180                                   0 / 1012                                       \norg.apache.spark.sql.catalyst.analysis.TypeCoercionBase$WidenSetOperationTypes                     0 / 189998057                                   0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.ResolveSessionCatalog                                       0 / 147808323                                   0 / 2023                                       \norg.apache.spark.sql.execution.aggregate.ResolveEncodersInScalaAgg                                 0 / 111655088                                   0 / 2023                                       \ncom.databricks.sql.transaction.tahoe.DeltaAnalysisEdge                                             0 / 111191419                                   0 / 1012                                       \norg.apache.spark.sql.catalyst.optimizer.OptimizeUpdateFields                                       0 / 67170132                                    0 / 1015                                       \norg.apache.spark.sql.catalyst.analysis.CleanupAliases                                              0 / 57840008                                    0 / 1012                                       \norg.apache.spark.sql.catalyst.optimizer.Optimizer$FinishAnalysis                                   0 / 48559187                                    0 / 1                                          \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAliases                                     42812041 / 47655431                             1 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveBinaryArithmetic                            0 / 41456496                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveDeserializer                                33435020 / 40820631                             1 / 2023                                       \norg.apache.spark.sql.execution.datasources.FindDataSourceTable                                     0 / 40696654                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.ResolveCatalogs                                             0 / 34744862                                    0 / 2023                                       \ncom.databricks.sql.dlt.EventLogAnalysis                                                            0 / 34723593                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.optimizer.OptimizeOneRowRelationSubquery                             0 / 32749620                                    0 / 1                                          \norg.apache.spark.sql.catalyst.analysis.ResolveDefaultColumns                                       0 / 29645248                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.optimizer.ColumnPruning                                              26381258 / 27419552                             1 / 6                                          \norg.apache.spark.sql.catalyst.optimizer.ConvertToLocalRelation                                     21791314 / 26681456                             1 / 3                                          \norg.apache.spark.sql.execution.datasources.DataSourceAnalysis                                      0 / 26481790                                    0 / 1012                                       \norg.apache.spark.sql.hive.RelationConversions                                                      0 / 24470702                                    0 / 1012                                       \ncom.databricks.sql.managedcatalog.ResolveWithCredential                                            0 / 24345128                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveFieldNameAndPosition                        0 / 23528413                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveTimeTravel                                  0 / 22878004                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.optimizer.BooleanSimplification                                      0 / 22867558                                    0 / 5                                          \norg.apache.spark.sql.catalyst.optimizer.PushDownPredicates                                         21362119 / 21581414                             1 / 8                                          \ncom.databricks.sql.optimizer.FilterReduction                                                       0 / 21296256                                    0 / 3                                          \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveFunctions                                   0 / 20878683                                    0 / 2023                                       \ncom.databricks.sql.acl.InlineUserInfoExpressions                                                   0 / 20673149                                    0 / 2023                                       \ncom.databricks.sql.optimizer.RangeJoinRewrite                                                      0 / 20233964                                    0 / 1                                          \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveUpCast                                      11258335 / 19420216                             1 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.ResolveLambdaVariables                                      0 / 18598490                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$SparkServiceStatementSubstitution                  0 / 17034267                                    0 / 1012                                       \norg.apache.spark.sql.execution.datasources.ApplyCharTypePadding                                    0 / 16999238                                    0 / 1012                                       \norg.apache.spark.sql.catalyst.analysis.ResolveExpressionsWithNamePlaceholders                      0 / 16940442                                    0 / 2023                                       \ncom.databricks.sql.transaction.tahoe.stats.PrepareDeltaScan                                        0 / 16781581                                    0 / 1                                          \ncom.databricks.sql.cloudfiles.CloudFilesAnalysis                                                   0 / 16311568                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.optimizer.MergeScalarSubqueries                                      0 / 15772720                                    0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.PruneFilters                                               0 / 15726946                                    0 / 4                                          \norg.apache.spark.sql.catalyst.analysis.RewriteDeleteFromTable                                      0 / 15449573                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.optimizer.NullPropagation                                            0 / 15386980                                    0 / 4                                          \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveUnpivot                                     0 / 14818498                                    0 / 2023                                       \norg.apache.spark.sql.execution.streaming.ResolveWriteToStream                                      0 / 14503091                                    0 / 2023                                       \norg.apache.spark.sql.execution.datasources.PreprocessTableInsertion                                0 / 14268214                                    0 / 1012                                       \norg.apache.spark.sql.catalyst.optimizer.InferFiltersFromConstraints                                0 / 14180690                                    0 / 2                                          \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveInsertInto                                  0 / 13588305                                    0 / 2023                                       \ncom.databricks.sql.optimizer.SpecializeScalaUDF                                                    0 / 13552775                                    0 / 1                                          \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolvePivot                                       0 / 13445763                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.TimeWindowing                                               0 / 13143820                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.ResolveLateralColumnAliasReference                          0 / 12590950                                    0 / 2023                                       \norg.apache.spark.sql.execution.datasources.ResolveSQLOnFile                                        0 / 12374349                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.UpdateOuterReferences                                       0 / 12145463                                    0 / 1012                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$GlobalAggregates                                   0 / 12023896                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.EvalSubqueriesForTimeTravel                                 0 / 11913488                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.ResolveInlineTables                                         0 / 11629554                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.EliminateUnions                                             0 / 11574243                                    0 / 1012                                       \norg.apache.spark.sql.execution.datasources.v2.V2ScanRelationPushDown                               0 / 11421660                                    0 / 1                                          \norg.apache.spark.sql.catalyst.analysis.RemoveTempResolvedColumn                                    0 / 11053796                                    0 / 1012                                       \norg.apache.spark.sql.hive.ResolveHiveSerdeTable                                                    0 / 10809704                                    0 / 2023                                       \norg.apache.spark.sql.execution.datasources.PreprocessTableCreation                                 0 / 10588453                                    0 / 1012                                       \norg.apache.spark.sql.execution.datasources.SchemaPruning                                           0 / 10533042                                    0 / 1                                          \norg.apache.spark.sql.catalyst.analysis.SubstituteUnresolvedOrdinals                                0 / 10499300                                    0 / 1012                                       \ncom.databricks.sql.analyzer.ResolveRangeJoinHints                                                  0 / 10408602                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveSQLFunctions                                0 / 10378422                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.BindParameters                                              0 / 10298830                                    0 / 1012                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ExtractGenerator                                   0 / 10140184                                    0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions                                    0 / 10131613                                    0 / 1012                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveNewInstance                                 0 / 9845630                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGenerate                                    0 / 9729908                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveQualify                                     0 / 9668136                                     0 / 2023                                       \ncom.databricks.sql.transaction.tahoe.PreprocessTableUpdateEdge                                     0 / 9646134                                     0 / 1012                                       \ncom.databricks.sql.expressions.ExtractSemiStructuredFields                                         0 / 9640428                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveAggregateFunctions                          0 / 9545070                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ExtractWindowExpressions                           0 / 9512871                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveSubquery                                    0 / 9427972                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveUserSpecifiedColumns                        0 / 9256637                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveSQLTableFunctions                           0 / 9244283                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.SessionWindowing                                            0 / 8855248                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$WindowsSubstitution                                0 / 8851552                                     0 / 1012                                       \ncom.databricks.sql.acl.ResolvePermissionManagement                                                 0 / 8732467                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.optimizer.SimplifyExtractValueOps                                    0 / 8700220                                     0 / 3                                          \norg.apache.spark.sql.catalyst.analysis.KeepLegacyOutputs                                           0 / 8667438                                     0 / 1012                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveWindowFrame                                 0 / 8633705                                     0 / 2023                                       \norg.apache.spark.sql.hive.DetermineTableStats                                                      0 / 8591366                                     0 / 1012                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveOrdinalInOrderByAndGroupBy                  0 / 8533132                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$HandleNullInputsForUDF                             0 / 8323138                                     0 / 1012                                       \norg.apache.spark.sql.execution.datasources.v2.V2Writes                                             0 / 8225169                                     0 / 1                                          \norg.apache.spark.sql.catalyst.analysis.ResolveHints$ResolveDynamicPartitionPruningHints            0 / 8203176                                     0 / 1012                                       \norg.apache.spark.sql.catalyst.analysis.PullOutNondeterministic                                     0 / 8158724                                     0 / 1012                                       \ncom.databricks.sql.expressions.OptimizeMultiSemiStructuredExtract                                  0 / 8140386                                     0 / 1                                          \norg.apache.spark.sql.catalyst.analysis.ResolveWithCTE                                              0 / 8095917                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveSubqueryColumnAliases                       0 / 8088828                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.ResolveUnion                                                0 / 7943059                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.ResolvePartitionSpec                                        0 / 7915851                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.optimizer.RewriteLateralSubquery                                     0 / 7912265                                     0 / 3                                          \ncom.databricks.service.ClientPlaceholderAnalysis                                                   0 / 7885545                                     0 / 1012                                       \norg.apache.spark.sql.catalyst.analysis.TypeCoercionBase$UnpivotCoercion                            0 / 7883679                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.optimizer.OptimizeCsvJsonExprs                                       0 / 7816543                                     0 / 3                                          \norg.apache.spark.sql.execution.datasources.FallBackFileSourceV2                                    0 / 7653348                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.optimizer.RewriteCorrelatedScalarSubquery                            0 / 7577818                                     0 / 3                                          \norg.apache.spark.sql.catalyst.analysis.ResolveWindowTime                                           0 / 7544768                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.ResolveHints$ResolveJoinStrategyHints                       0 / 7534994                                     0 / 1012                                       \norg.apache.spark.sql.execution.datasources.PruneFileSourcePartitions                               0 / 7500260                                     0 / 1                                          \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveWindowOrder                                 0 / 7499381                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.ResolveCommandsWithIfExists                                 0 / 7416732                                     0 / 1012                                       \ncom.databricks.sql.analyzer.CheckNestedRowColumnAccess                                             0 / 7326413                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.ResolveHints$RemoveAllHints                                 0 / 7222568                                     0 / 1012                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveNaturalAndUsingJoin                         0 / 7091424                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveOutputRelation                              0 / 7061183                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.optimizer.NullDownPropagation                                        0 / 6958195                                     0 / 3                                          \norg.apache.spark.sql.catalyst.analysis.ResolveHints$ResolveCoalesceHints                           0 / 6927160                                     0 / 1012                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$HandleSpecialCommand                               0 / 6863345                                     0 / 1012                                       \norg.apache.spark.sql.catalyst.analysis.ResolveHints$DisableHints                                   0 / 6793907                                     0 / 1012                                       \ncom.databricks.sql.transaction.tahoe.PreprocessTableMergeEdge                                      0 / 6671055                                     0 / 1012                                       \norg.apache.spark.sql.catalyst.analysis.Analyzer$ResolveGroupingAnalytics                           0 / 6651561                                     0 / 2023                                       \norg.apache.spark.sql.catalyst.optimizer.CollapseProject                                            6488306 / 6554753                               1 / 5                                          \ncom.databricks.sql.transaction.tahoe.PreprocessTableDeleteEdge                                     0 / 6416023               \n\n*** WARNING: max output size exceeded, skipping output. ***\n\n                                 \norg.apache.spark.sql.catalyst.expressions.codegen.package$ExpressionCanonicalizer$CleanExpressions 0 / 3741837                                     0 / 3                                          \ncom.databricks.sql.optimizer.SimplifyStringFunctions                                               0 / 3732446                                     0 / 3                                          \ncom.databricks.sql.optimizer.CombineApproximatePercentileAggregates                                0 / 3722593                                     0 / 3                                          \ncom.databricks.sql.optimizer.FilterPredicateSimplification                                         0 / 3700073                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.RemoveNoopOperators                                        0 / 3599791                                     0 / 7                                          \ncom.databricks.sql.optimizer.OptimizeArrayNullCheck                                                0 / 3599508                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.RewriteExceptAll                                           0 / 3595965                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.PushFoldableIntoBranches                                   0 / 3587839                                     0 / 3                                          \ncom.databricks.sql.optimizer.SkewJoinRewrite                                                       0 / 3562893                                     0 / 1                                          \ncom.databricks.sql.optimizer.EliminateRedundantAggregatePart                                       0 / 3542678                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.InjectRuntimeFilter                                        0 / 3529889                                     0 / 2                                          \norg.apache.spark.sql.catalyst.optimizer.CombineConcats                                             0 / 3508284                                     0 / 3                                          \norg.apache.spark.sql.catalyst.analysis.CTESubstitution                                             0 / 3448289                                     0 / 1012                                       \norg.apache.spark.sql.catalyst.optimizer.EliminateOuterJoin                                         0 / 3406899                                     0 / 3                                          \ncom.databricks.sql.optimizer.SimplifyRLike                                                         0 / 3392660                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.SimplifyCaseConversionExpressions                          0 / 3380324                                     0 / 3                                          \ncom.databricks.sql.optimizer.PushDownExtractValueExpressions                                       0 / 3375805                                     0 / 3                                          \ncom.databricks.sql.optimizer.PushExtractValueIntoArrayTransform                                    0 / 3370362                                     0 / 3                                          \norg.apache.spark.sql.execution.dynamicpruning.PartitionPruning                                     0 / 3365095                                     0 / 1                                          \ncom.databricks.sql.optimizer.EliminateNullCheckForExtractValue                                     0 / 3340182                                     0 / 3                                          \norg.apache.spark.sql.execution.datasources.v2.GroupBasedRowLevelOperationScanPlanning              0 / 3326189                                     0 / 1                                          \norg.apache.spark.sql.execution.dynamicpruning.CleanupDynamicPruningFilters                         0 / 3325030                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.RemoveDispensableExpressions                               0 / 3284453                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.LimitPushDownThroughWindow                                 0 / 3201376                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.PushLeftSemiLeftAntiThroughJoin                            0 / 3128912                                     0 / 3                                          \ncom.databricks.sql.optimizer.PushLimitIntoAggregate                                                0 / 3101399                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.RemoveRedundantAggregates                                  0 / 3090946                                     0 / 4                                          \norg.apache.spark.sql.catalyst.optimizer.SimplifyConditionals                                       0 / 3039644                                     0 / 3                                          \ncom.databricks.sql.optimizer.ComplexTypeMinMax                                                     0 / 2969085                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.SimplifyBinaryComparison                                   0 / 2966387                                     0 / 3                                          \ncom.databricks.sql.optimizer.PropagateEmptyRelationThroughAggregate                                0 / 2958843                                     0 / 2                                          \norg.apache.spark.sql.hive.execution.PruneHiveTablePartitions                                       0 / 2955526                                     0 / 1                                          \ncom.databricks.sql.optimizer.DynamicFilterPropagation                                              0 / 2944549                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.EliminateLimits                                            0 / 2875162                                     0 / 3                                          \ncom.databricks.sql.optimizer.JoinORExpansion                                                       0 / 2839744                                     0 / 1                                          \ncom.databricks.sql.optimizer.EliminateSecureViewNode                                               0 / 2823451                                     0 / 3                                          \ncom.databricks.sql.optimizer.OptimizeArrayContains                                                 0 / 2794119                                     0 / 3                                          \norg.apache.spark.sql.catalyst.plans.logical.ConvertSecureViewLeafNodeToUnaryNode                   0 / 2773168                                     0 / 2                                          \norg.apache.spark.sql.catalyst.optimizer.OptimizeRand                                               0 / 2753819                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.CombineUnions                                              0 / 2744965                                     0 / 4                                          \norg.apache.spark.sql.catalyst.optimizer.GenerateOptimization                                       0 / 2711125                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.ObjectSerializerPruning                                    0 / 2697964                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.PushProjectionThroughLimit                                 0 / 2696874                                     0 / 5                                          \ncom.databricks.sql.optimizer.FilePruning                                                           0 / 2669704                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.CollapseRepartition                                        0 / 2668030                                     0 / 3                                          \ncom.databricks.sql.optimizer.ConvertCollectSetToCollectListDistinct                                0 / 2639728                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.RemoveLiteralFromGroupExpressions                          0 / 2636623                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.ReplaceUpdateFieldsExpression                              0 / 2636000                                     0 / 1                                          \ncom.databricks.sql.optimizer.SimplifyRegExpReplace                                                 0 / 2625001                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.NormalizeFloatingNumbers                                   0 / 2602461                                     0 / 1                                          \norg.apache.spark.sql.execution.python.ExtractPythonUDFFromAggregate                                0 / 2600681                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.Optimizer$OptimizeSubqueries                               0 / 2549987                                     0 / 1                                          \ncom.databricks.sql.optimizer.CollapseMultipleWindowSpec                                            0 / 2521917                                     0 / 1                                          \ncom.databricks.sql.analyzer.CheckRowColumnAccessFunctionsInReferencedTables                        0 / 2493040                                     0 / 2023                                       \ncom.databricks.sql.optimizer.OptimizeCase                                                          0 / 2491480                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.LikeSimplification                                         0 / 2459341                                     0 / 3                                          \ncom.databricks.sql.optimizer.EdgeNormalizeExpressions                                              0 / 2448292                                     0 / 3                                          \ncom.databricks.sql.optimizer.EliminateRedundantDistinctInAggregateFunction                         0 / 2447383                                     0 / 3                                          \ncom.databricks.sql.optimizer.NormalizeAggregateFilter                                              0 / 2427637                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.DecimalAggregates                                          0 / 2389282                                     0 / 1                                          \ncom.databricks.sql.optimizer.ReplaceEqualToWithNullEqInJoin                                        0 / 2386875                                     0 / 3                                          \ncom.databricks.sql.optimizer.OptimizeArraySize                                                     0 / 2366092                                     0 / 1                                          \ncom.databricks.sql.optimizer.PushDownGetArrayItemToStringSplit                                     0 / 2345971                                     0 / 3                                          \ncom.databricks.sql.optimizer.OptimizeSample                                                        0 / 2336698                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.ReplaceIntersectWithSemiJoin                               0 / 2278254                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.FoldablePropagation                                        0 / 2264107                                     0 / 4                                          \norg.apache.spark.sql.catalyst.optimizer.ReorderAssociativeOperator                                 0 / 2214737                                     0 / 3                                          \ncom.databricks.sql.optimizer.FoldEmptyAggregate                                                    0 / 2156487                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.OptimizeOneRowPlan                                         0 / 2148547                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.ReplaceExceptWithAntiJoin                                  0 / 2142838                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.EliminateOffsets                                           0 / 2073146                                     0 / 3                                          \ncom.databricks.sql.optimizer.SimplifyUnderscoreLike                                                0 / 2049423                                     0 / 3                                          \ncom.databricks.sql.optimizer.ReduceSubstringMaterialization                                        0 / 2045749                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.CleanUpTempCTEInfo                                         0 / 2040528                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.RemoveRepetitionFromGroupExpressions                       0 / 1981581                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.RewriteDistinctAggregates                                  0 / 1964544                                     0 / 2                                          \norg.apache.spark.sql.catalyst.optimizer.CombineTypedFilters                                        0 / 1893186                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.ReplaceDistinctWithAggregate                               0 / 1869747                                     0 / 1                                          \ncom.databricks.sql.transaction.tahoe.perf.DescribeHistoryLimitPushdown                             0 / 1833879                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.OptimizeIn                                                 0 / 1828756                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.OptimizeRepartition                                        0 / 1824699                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.PushProjectionThroughUnion                                 0 / 1781694                                     0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.EliminateMapObjects                                        0 / 1759942                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.ReplaceExceptWithFilter                                    0 / 1738433                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.ReplaceDeduplicateWithAggregate                            0 / 1692969                                     0 / 1                                          \norg.apache.spark.sql.execution.datasources.V1Writes                                                0 / 1672403                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.ReassignLambdaVariableID                                   0 / 1545192                                     0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.RemoveNoopUnion                                            0 / 1517202                                     0 / 1                                          \ncom.databricks.sql.optimizer.ExtractPythonUDFFromWindow                                            0 / 1487939                                     0 / 1                                          \norg.apache.spark.sql.execution.python.ExtractGroupingPythonUDFFromAggregate                        0 / 1261261                                     0 / 1                                          \norg.apache.spark.sql.execution.python.ExtractPythonUDFs                                            0 / 942502                                      0 / 1                                          \ncom.databricks.sql.optimizer.ConvertInnerToSemiJoins                                               0 / 931272                                      0 / 1                                          \norg.apache.spark.sql.execution.dynamicpruning.RowLevelOperationRuntimeGroupFiltering               0 / 856937                                      0 / 1                                          \ncom.databricks.sql.streaming.perf.MoveOptimizedForEachBatchFastpathToRoot                          0 / 632550                                      0 / 1                                          \ncom.databricks.sql.optimizer.RangePartitionIdRewrite                                               0 / 610204                                      0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.RemoveRedundantAliases                                     0 / 548123                                      0 / 5                                          \norg.apache.spark.sql.catalyst.optimizer.CombineFilters                                             0 / 526285                                      0 / 4                                          \ncom.databricks.sql.optimizer.OptimizeLimit                                                         0 / 483830                                      0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.EliminateSorts                                             0 / 345378                                      0 / 1                                          \ncom.databricks.sql.optimizer.CombineCountSumAverage                                                0 / 202404                                      0 / 3                                          \ncom.databricks.sql.optimizer.OptimizeGroupByChain                                                  0 / 152692                                      0 / 4                                          \ncom.databricks.sql.optimizer.ShuffleAndReduceDivisions                                             0 / 94554                                       0 / 3                                          \ncom.databricks.sql.execution.safespark.IsolatePysparkUDFs                                          0 / 88492                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.DisableExpressionCodegenOverLocalRelations                 0 / 70498                                       0 / 1                                          \ncom.databricks.sql.optimizer.PredicateReorder                                                      0 / 66480                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.CheckCartesianProducts                                     0 / 65306                                       0 / 2                                          \ncom.databricks.sql.optimizer.CollectDynamicPruningBroadcastKeys                                    0 / 64801                                       0 / 1                                          \ncom.databricks.service.CheckProtoSerializable                                                      0 / 62556                                       0 / 1                                          \ncom.databricks.sql.optimizer.AggregatePushdown                                                     0 / 57064                                       0 / 1                                          \ncom.databricks.aether.experimental.InsertMetadataSubplans                                          0 / 56963                                       0 / 1                                          \ncom.databricks.sql.optimizer.TransformShrinkingToGrowing                                           0 / 52806                                       0 / 1                                          \ncom.databricks.sql.optimizer.RewriteCastAsTryCast                                                  0 / 52473                                       0 / 3                                          \ncom.databricks.sql.io.parquet.ParquetSchemaPruning                                                 0 / 46487                                       0 / 1                                          \ncom.databricks.service.ConvertRemoteExec                                                           0 / 33661                                       0 / 1                                          \ncom.databricks.sql.execution.safespark.ExtractExternalUDFs                                         0 / 31227                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.SimplifyCasts                                              0 / 31170                                       0 / 3                                          \ncom.databricks.sql.streaming.perf.InjectOptimizedForEachBatchFastpathNodeToInnerQuery              0 / 30485                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.ReplaceCTERefWithRepartition                               0 / 24208                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin                                   0 / 21748                                       0 / 1                                          \norg.apache.spark.sql.execution.OptimizeMetadataOnlyQuery                                           0 / 21007                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.PushPredicateThroughNonJoin                                0 / 17897                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.PullOutGroupingExpressions                                 0 / 17232                                       0 / 3                                          \norg.apache.spark.sql.catalyst.optimizer.PushdownPredicatesAndPruneColumnsForCTEDef                 0 / 16579                                       0 / 3                                          \ncom.databricks.sql.optimizer.CaseWhenToMapLookUp                                                   0 / 14851                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.Optimizer$UpdateCTERelationStats                           0 / 13320                                       0 / 1                                          \ncom.databricks.sql.streaming.perf.CollapseOptimizedForEachBatchFastpath                            0 / 11463                                       0 / 1                                          \norg.apache.spark.sql.catalyst.optimizer.InlineCTE                                                  0 / 6430                                        0 / 1                                          \ncom.databricks.service.NoOpRule                                                                    0 / 6040                                        0 / 4                                          \n     \n"
     ]
    }
   ],
   "source": [
    "# Checking time taken by rule executor for withColumns\n",
    "from pyspark.sql.functions import *\n",
    " \n",
    "df_1 = spark.sql(\"\"\"select * from samples.tpch.customer\"\"\")\n",
    "\n",
    "# lets create 300 dummy column list\n",
    "dummy_col_list = [f\"foo{i}\" for i in range(1,1001)]\n",
    "\n",
    "dummy_col_val_map = {cname: lit(None).cast('string') for cname in dummy_col_list}\n",
    "\n",
    "# Get JVM reference\n",
    "jvm = spark.sparkContext._jvm\n",
    "\n",
    "# Access Scala package/class\n",
    "catalyst_rule_executor = jvm.org.apache.spark.sql.catalyst.rules.RuleExecutor\n",
    "\n",
    "# Adding 300 columns\n",
    "df_2 = df_1.withColumns(dummy_col_val_map)\n",
    "\n",
    "print(catalyst_rule_executor.dumpTimeSpent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0423e95-d502-4502-a328-b3b27790e5d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "withColumns",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
